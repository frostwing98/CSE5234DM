{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CSE 5243 - Introduction to Data Mining\n",
    "## Homework 2: Classification\n",
    "- Semester: Fall 2022\n",
    "- Instructor: Greg Ryslik\n",
    "- Section: Wednesday 12:45\n",
    "- Student Name: John Smith\n",
    "- Name.#: smith.2@osu.edu\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Objectives\n",
    "\n",
    "In this lab, you will use the \"Cleveland Data CLEANED AND TRIMMED.csv\" heart disease dataset provided on Carmen.  It is a subset of the \"Cleveland\" dataset that can be found here: https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "You will configure, execute, and evaluate an off-the-shelf K-Nearest-Neighbor classifier and two other classifiers you choose.\n",
    "\n",
    "The objectives of this assignment are:\n",
    "1.\tUnderstand how to evaluate classifiers based on business criteria.\n",
    "2.\tUnderstand how to tune and evaluate a classifier to achieve good performance.\n",
    "3.\tUnderstand how to select and evaluate suitable off-the-shelf classifiers based on the characteristics of a dataset and the outcomes you need.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "You work for a medical institution that wants to improve the heart health of its patients.  You have obtained a dataset that contains a variety of demographic and health-related information for a group of patients.  It also includes a CLASS variable \"num\" that indicates the heart health of each of the patients.  The values are:\n",
    "\n",
    "0. No heart health issues / risk\n",
    "1. Slight heart health issues / risk\n",
    "2. Moderate heart health issues / risk\n",
    "3. High heart health issues / risk\n",
    "4. Extreme heart health issue / risk\n",
    "\n",
    "You have been asked to develop a classifier based on the dataset data, to predict the CLASS of new patients so they can be enrolled in interventions based on their demographic data.\n",
    "\n",
    "The COSTs of the interventions are as follows, based on the predicted class of each patient\n",
    "\n",
    "0) Tiny intervention: 100 (dollars)\n",
    "1) Minor intervention: 200\n",
    "2) Moderate intervention: 300\n",
    "3) Significant intervention: 400\n",
    "4) Extreme intervention: 500\n",
    "\n",
    "The BENEFITs of the interventions are as follows:\n",
    "\n",
    "- If the classification is correct and the correct intervention given to the patient: 500 * (TRUE_CLASS + 1)\n",
    "- If an incorrect classification is made and the wrong intervention is given to the patient: 0\n",
    "\n",
    "You would like to find a classifier that maximizes the overall **NET_BENEFIT = BENEFIT - COST**. Therefore, a larger positive number is a good outcome.\n",
    "\n",
    "So, for example:\n",
    "\n",
    "- If a patient's true class is 4 and their predicted class is 0, their NET_BENEFIT = 0 - 100 = -100\n",
    "- If a patient's true class is 4 and they are correctly classified, their NET_BENEFIT is 500*(4+1) - 500 = 2000\n",
    "\n",
    "The medical institution would like you to evaluate the use of a K-Nearest-Neighbor classifier as a starting point.  You agree to do so, as long as you then can choose a different classifier if you are not satisfied with KNN.\n",
    "\n",
    "### Collaboration\n",
    "For this assignment, you should work as an individual. You may informally discuss ideas with classmates, but your work should be your own.\n",
    "\n",
    "### What you need to turn in:\n",
    "1)\tCode\n",
    "\n",
    "-\tFor this homework, the code is the Jupyter Notebook.  Use the provided Jupyter Notebook template, and fill in the appropriate information.\n",
    "-\tYou may use common Python libraries for I/O, data manipulation, data visualization, etc. (e.g., NumPy, Pandas, MatPlotLib,…  See reference below.) \n",
    "-\tYou may not use library operations that perform, in effect, the “core” computations for this homework (e.g., If the assignment is to write a K-Means algorithm, you may not use a library operation that, in effect, does the core work needed to implement a K-Means algorithm.).  When in doubt, ask the grader or instructor.\n",
    "-\tThe code must be written by you, and any significant code snips you found on the Internet and used to understand how to do your coding for the core functionality must be attributed.  (You do not need to attribute basic functionality – matrix operations, IO, etc.)\n",
    "-\tThe code must be commented sufficiently to allow a reader to understand the algorithm without reading the actual Python, step by step.\n",
    "-\tWhen in doubt, ask the grader or instructor.\n",
    "\n",
    "2)\tWritten Report\n",
    "-\tFor this homework, the report is the Jupyter Notebook.  The report should be well-written.  Please proof-read and remove spelling and grammar errors and typos.\n",
    "-\tThe report should discuss your analysis and observations. Key points and findings must be written in a style suitable for consumption by non-experts.  Present charts and graphs to support your observations. If you performed any data processing, cleaning, etc., please discuss it within the report.\n",
    "\n",
    "### Grading\n",
    "\n",
    "1.\tOverall readability and organization of your report (5%)\n",
    "> - Is it well organized and does the presentation flow in a logical manner?\n",
    "> - Are there no grammar and spelling mistakes?\n",
    "> - Do the charts/graphs relate to the text?\n",
    "> - Are the summarized key points and findings understandable by non-experts?\n",
    "> - Do the Overview and Conclusions provide context for the entire exercise?\n",
    "2.\tEvaluation Method (10%)\n",
    "> - Does your evaluation method meet the needs of the developer (you) as well as the needs of your business stakeholders?\n",
    "> - Is the evaluation method sound?\n",
    "> - Did you describe both the method itself and why you chose it?\n",
    "3.\tPre-Processing of the Dataset (10%)\n",
    "> - Did you make reasonable choices for pre-processing, and explain why you made them?\n",
    "4.\tEvaluation of the KNN Classifier (20%)\n",
    "> - Is your algorithm design and coding correct?\n",
    "> - Is it well documented?\n",
    "> - Have you made an effort to tune it for good performance?\n",
    "> - Is the evaluation sound?\n",
    "5.\tEvaluation of the Second Classifier (20%)\n",
    "> - Is your algorithm design and coding correct?\n",
    "> - Is it well documented?\n",
    "> - Have you made an effort to tune it for good performance?\n",
    "> - Is the evaluation sound?\n",
    "6.\tEvaluation of the Third Classifier (20%)\n",
    "> - Is your algorithm design and coding correct?\n",
    "> - Is it well documented?\n",
    "> - Have you made an effort to tune it for good performance?\n",
    "> - Is the evaluation sound?\n",
    "7.\tComparison of the Three Classifiers (10%)\n",
    "> - Is the comparison sound?\n",
    "> - Did you choose a specific classifier as best and explain why?\n",
    "8.  Conclusions (5%)\n",
    "> - Did you summarize appropriately your critical findings. \n",
    "> - Did you provide appropriate conclusions and next steps.\n",
    "\n",
    "### How to turn in your work on Carmen:\n",
    "\n",
    "Submit to Carmen the Jupyter Notebook, the html print out of your Jupyter notebook, and any supporting files that you used to process and analyze this data. You do not need to include the input data.  All submitted files (code and/or report) except for the data should be archived in a *.zip file, and submitted via Carmen.  Use this naming convention:\n",
    " \n",
    "•\tHW2_Surname_DotNumber.zip\n",
    "\n",
    "The submitted file should be less than 10MB.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Section: Overview\n",
    "- Insert a short description of the scope of this exercise, any supporting information, etc.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: Setup\n",
    "- Add any needed imports, helper functions, etc., here.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 1 - Evaluation Method\n",
    "- Define measures for evaluating the classification models you develop.  Explain why the measures you choose provide a useful view into the value and usefulness of the model you eventually chose for the company to use.  Define two types:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 1.1 - Define measures that do not include the cost information\n",
    "- (e.g., confusion matrices, accuracy, precision, recall, F-measures, etc.).\n",
    "- Consider using: from sklearn.metrics import classification_report, confusion_matrix\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 1.2 - Define measures that do include the cost information\n",
    "- (e.g., using cost matrices).\n",
    "- Consider creating a function that takes a confusion matrix and calculates the cost, like this:\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_cost(conf_matrix):\n",
    "# # Fill in the cost matrix values\n",
    "# #                           PREDICTED VALUES\n",
    "# #                      0     1     2     3     4\n",
    "#     cost_matrix = [[1234, 1234, 1234, 1234, 1234],   # 0\n",
    "#                    [1234, 1234, 1234, 1234, 1234],   # 1\n",
    "#                    [1234, 1234, 1234, 1234, 1234],   # 2  TRUE VALUES\n",
    "#                    [1234, 1234, 1234, 1234, 1234],   # 3\n",
    "#                    [1234, 1234, 1234, 1234, 1234]]   # 4\n",
    "#     total = 0\n",
    "#     for r in range(0, 5):\n",
    "#         for c in range(0, 5):\n",
    "#             total = total + cost_matrix[r][c] * conf_matrix[r][c]\n",
    "\n",
    "# # OR... THIS WORKS      total = np.dot(np.array(conf_matrix).ravel(), np.array(cost_matrix).ravel())\n",
    "#     return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 2 - Pre-Processing of the Dataset\n",
    "- Use the provided dataset.  Split it into a Training dataset and a Test dataset based on the class attribute.  Keep them separate and use the Training dataset for training/tuning and the Test dataset for testing. For consistency, use the **train_test_split** operation available in SciKit Learn (use a specific random seed, so it is reproducible).\n",
    "  - from sklearn.model_selection import train_test_split\n",
    "  - X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.1 - Explore the attributes\n",
    "- As in Homework 1, explore the attributes briefly. Reference the website listed in the Introduction.\n",
    "- Provide basic statistics for the attributes.\n",
    "- List which attributes are Nominal (even though they are encoded as numbers), Ordinal, Interval, Ratio.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.2 - Revise the dataset\n",
    "- Review the meanings of the attributes and consider removing redundant or (likely) irrelevant attributes, combining attributes, etc., to reduce the number of attributes.\n",
    "- (You may choose to use techniques such as those you used in Homework 1 to analyze the impacts of individual attributes on the CLASS attribute, but you need not do a “deep” analysis.)\n",
    "- Describe what you chose to do (and not do), and why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.3 - Transform the attributes\n",
    "- Consider transforming the remaining attributes (e.g., using the data dictionary to replace the numbers with text values for some attributes – this might or might not be useful), normalizing / scaling values, encoding labels (if necessary), etc.\n",
    "- Describe what you chose to do (and not do), and why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 3 - Evaluation of the Off-The-Shelf KNN Classifier\n",
    "- Select the KNN classifier from the SciKit Learn library and run it on the dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.1 - Configure the off-the-shelf KNN classifier\n",
    "- Use the KNeighborsClassifier from the SciKit Learn library\n",
    "- Explain all setup, parameters and execution options you chose to set, and why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.2 - Run and evaluate the classifier\n",
    "- Try several values of the K parameter and compare the results.\n",
    "- Evaluate the performance of the classifier, using the evaluation method you defined above.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.3 - Evaluate the choice of the KNN classifier\n",
    "- What characteristics of the problem and data made KNN a good or bad choice?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 4 - Evaluation of Off-The-Shelf Classifier #2\n",
    "- As with the KNN classifier above, choose another classifier from the SciKit Learn library (Decision Tree, SVM, Logistic Regression, etc.) and run it on the dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.1 - Configure the classifier\n",
    "- Use the appropriate classifier from the SciKit Learn library.\n",
    "- Explain all setup, parameters and execution options you chose to set, and why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.2 - Run and evaluate the classifier\n",
    "- Try several values of the parameters (if appropriate) and compare the results.\n",
    "- Evaluate the performance of the classifier, using the evaluation method you defined above.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.3 - Evaluate the choice of the classifier\n",
    "- What characteristics of the problem and data made the classifier a good or bad choice?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 5 - Evaluation of Off-The-Shelf Classifier #3\n",
    "- As with the KNN classifier above, choose another classifier from the SciKit Learn library (Decision Tree, SVM, Logistic Regression, etc.) and run it on the dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.1 - Configure the classifier\n",
    "- Use the appropriate classifier from the SciKit Learn library.\n",
    "- Explain all setup, parameters and execution options you chose to set, and why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.2 - Run and evaluate the classifier\n",
    "- Try several values of the parameters (if appropriate) and compare the results.\n",
    "- Evaluate the performance of the classifier, using the evaluation method you defined above.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.3 - Evaluate the choice of the classifier\n",
    "- What characteristics of the problem and data made the classifier a good or bad choice?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 6 - Comparison of the Three Classifiers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 6.1 - Compare the performance of these classifiers to each other\n",
    "- What are their strong and weak points?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 6.2 - Choose a Best Classifier\n",
    "- Choose one of the three classifiers as best and explain why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 7 - Conclusions\n",
    "- Write a paragraph on what you discovered or learned from this homework.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### END-OF-SUBMISSION\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
